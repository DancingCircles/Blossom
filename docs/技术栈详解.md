# Bullbell 项目技术栈详解

> 本文档详细说明项目中每个技术的作用、使用场景和企业实践，适合面试准备和技术理解。

---

## 📋 目录

1. [后端核心层](#1-后端核心层)
2. [数据存储层](#2-数据存储层)
3. [消息队列与数据同步](#3-消息队列与数据同步)
4. [监控运维层](#4-监控运维层)
5. [容器化部署](#5-容器化部署)
6. [前端技术](#6-前端技术)
7. [完整数据流](#7-完整数据流)

---

## 1. 后端核心层

### 1.1 Go 语言

**在本项目中的作用：**
- 项目的核心编程语言
- 实现所有后端业务逻辑：用户认证、话题管理、评论系统、投票功能
- 协调各个中间件（MySQL、Redis、ES、Kafka）
- 提供 RESTful API 供前端调用

**企业中的常见用途：**
- **微服务开发**：云原生时代的首选语言（Docker、Kubernetes 都是 Go 写的）
- **高并发服务**：电商秒杀、IM 即时通讯、直播推流
- **中间件开发**：消息队列、分布式存储、API 网关
- **DevOps 工具**：CI/CD 工具、监控系统、日志采集

**为什么选 Go：**
- 性能强：接近 C/C++，是 Python 的 10-50 倍
- 并发好：goroutine 轻量级协程，轻松支持百万并发
- 部署简单：编译成单个二进制文件，无需依赖环境
- 学习曲线平缓：语法简洁，标准库强大

**面试高频问题：**
- Go 的并发模型（goroutine、channel）
- Go 的 GC 机制
- Go 适合什么场景，不适合什么场景

---

### 1.2 Gin 框架

**在本项目中的作用：**
- Go 的 Web 框架，负责 HTTP 路由和请求处理
- 实现中间件：JWT 认证、跨域处理、限流、监控埋点
- 参数绑定和校验（用 Binding 验证用户输入）
- 统一的响应格式封装

**企业中的常见用途：**
- **RESTful API 开发**：后台管理系统、App 后端、小程序后端
- **BFF 层**（Backend For Frontend）：为前端提供专门的 API 聚合层
- **API 网关**：作为微服务的统一入口

**为什么选 Gin：**
- 性能第一：官方号称最快的 Go Web 框架
- 轻量级：只专注 HTTP 路由和中间件，不像 Beego 那么重
- 社区活跃：GitHub 70k+ stars，生态丰富
- 易于集成：支持各种中间件、日志、监控

**对比其他框架：**
- **Gin** → 性能优先，适合高并发 API
- **Beego** → 功能全面，类似 Django，适合快速开发
- **Echo** → 和 Gin 类似，但社区更小

---

## 2. 数据存储层

### 2.1 MySQL 8.0

**在本项目中的作用：**
- **唯一的真相源**（Single Source of Truth）
- 存储所有核心数据：用户表、话题表、评论表、投票表
- 保证数据完整性：事务（ACID）、外键约束、唯一索引
- 支持复杂查询：多表联查、聚合统计、分页排序

**企业中的常见用途：**
- **OLTP 业务**（在线事务处理）：订单系统、用户管理、财务系统
- **核心数据存储**：任何需要强一致性的数据
- **报表查询**：配合索引优化，支持千万级数据查询

**为什么 MySQL 是主数据库：**
- 成熟稳定：30 年历史，全球使用最广泛的数据库
- ACID 保证：转账、下单等关键操作不能丢数据
- 事务支持：多个操作要么全成功，要么全失败
- 社区和工具链完善：主从复制、分库分表、备份恢复

**面试高频问题：**
- 索引原理（B+树）
- 事务隔离级别
- 慢查询优化
- 主从复制原理
- binlog 的作用

---

### 2.2 Redis 7

**在本项目中的作用：**

#### 作用 1：缓存加速
- 缓存热门话题列表，避免每次查 MySQL
- 采用 Cache Aside 模式：先查缓存，miss 则查 DB 并写缓存
- 设置 5 分钟 TTL，防止数据过期

#### 作用 2：热榜排序
- 用 ZSet（有序集合）存储话题的热度分数
- 根据 Reddit 算法计算分数：`log10(投票数+1) / (时间差+2)^1.5`
- 定时任务每 5 分钟更新一次热榜

#### 作用 3：分布式锁
- 防止用户重复投票（点赞/点踩）
- 使用 SETNX + 过期时间实现
- 用 Lua 脚本保证原子性释放锁

#### 作用 4：限流
- 令牌桶算法，控制每秒最多 500 个请求
- 防止恶意刷接口

**企业中的常见用途：**
- **缓存层**：商品详情、用户信息、配置数据
- **会话存储**：用户登录态（Session、Token）
- **排行榜**：游戏排行、热搜榜、销量榜
- **计数器**：点赞数、浏览量、库存扣减
- **分布式锁**：防止超卖、防止重复提交
- **消息队列**：简单的发布订阅（Pub/Sub）
- **限流**：接口限流、用户行为限流

**为什么用 Redis：**
- 快：纯内存操作，读写速度 10 万 QPS 以上
- 数据结构丰富：String、Hash、List、Set、ZSet、Bitmap、HyperLogLog
- 持久化：RDB 快照 + AOF 日志，断电可恢复
- 高可用：主从复制、哨兵、Cluster 集群

**面试高频问题：**
- 缓存穿透、缓存击穿、缓存雪崩的解决方案
- Redis 单线程为什么快
- Redis 持久化机制（RDB vs AOF）
- 分布式锁的正确实现（Redlock）
- ZSet 的底层实现（跳表）

---

### 2.3 Elasticsearch 8.11

**在本项目中的作用：**
- 全文搜索引擎，支持话题搜索
- 支持中文分词：使用 ngram 分析器（可升级为 IK 中文分词）
- 模糊搜索：支持"游戏"搜到"Unity游戏开发"
- 高亮显示：搜索结果中关键词标红
- 相关性排序：最匹配的结果排在前面

**数据同步方式：**
- 通过 Canal 监听 MySQL binlog
- Canal 将变更推送到 Kafka
- 后端消费者从 Kafka 读取，实时更新 ES 索引

**企业中的常见用途：**
- **站内搜索**：电商商品搜索、内容搜索、日志搜索
- **日志分析**：ELK Stack（Elasticsearch + Logstash + Kibana）
- **实时监控**：系统指标分析、APM（应用性能监控）
- **推荐系统**：基于搜索历史做个性化推荐
- **业务分析**：用户行为分析、漏斗分析

**为什么不用 MySQL LIKE：**
- MySQL `LIKE '%keyword%'` 不走索引，全表扫描
- 不支持分词：搜"游戏"搜不到"Unity游戏开发"
- 不支持相关性排序：无法区分哪个结果更相关
- 性能差：百万数据查询要几秒

**为什么用 Elasticsearch：**
- 倒排索引：专门为搜索优化，毫秒级响应
- 分词器：支持中英文、拼音、同义词
- 分布式：横向扩展，支持 PB 级数据
- 实时性：近实时搜索（1 秒内可见）

**面试高频问题：**
- 倒排索引原理
- ES 的分片和副本
- 如何保证 MySQL 和 ES 的数据一致性
- 中文搜索的挑战和解决方案
- ES 深度分页问题（from + size）

---

## 3. 消息队列与数据同步

### 3.1 Kafka

**在本项目中的作用：**
- 作为数据同步的消息中间件
- 接收 Canal 发来的 MySQL 数据变更消息
- 缓冲消息，即使消费者宕机也不丢数据
- 削峰填谷：高峰期慢慢处理，不会压垮 ES

**消息流转：**
```
MySQL 数据变更 
  ↓ (binlog)
Canal 监听到变化
  ↓ (发送消息)
Kafka Topic
  ↓ (消费消息)
Go 消费者
  ↓ (写入)
Elasticsearch
```

**企业中的常见用途：**
- **异步解耦**：订单系统 → 发短信、发邮件、更新库存（各自独立消费）
- **削峰填谷**：秒杀场景，100 万请求进队列，慢慢处理
- **日志收集**：各个服务日志 → Kafka → ELK
- **数据同步**：MySQL → Kafka → 数据仓库（Hive、Clickhouse）
- **实时计算**：流式处理（Flink、Spark Streaming）
- **事件驱动架构**：用户注册 → 触发多个下游服务

**为什么用 Kafka：**
- 高吞吐：百万 QPS，适合大数据场景
- 持久化：消息写磁盘，支持消息重放
- 分区：支持并行消费，提高处理速度
- 可靠性：副本机制，不丢消息

**对比其他消息队列：**
- **Kafka** → 高吞吐、日志型、适合大数据
- **RabbitMQ** → 低延迟、功能丰富、适合业务消息
- **RocketMQ** → 阿里开源，适合电商、金融
- **Pulsar** → 新一代消息队列，计算存储分离

**面试高频问题：**
- Kafka 如何保证消息不丢失
- Kafka 如何保证消息不重复（幂等性）
- Kafka 的分区和消费者组
- Kafka 的高吞吐原理（零拷贝、批量发送）
- Kafka vs RabbitMQ 的区别

---

### 3.2 Canal

**在本项目中的作用：**
- 阿里开源的 MySQL binlog 解析工具
- 伪装成 MySQL 的从库，实时监听数据变化
- 捕获 INSERT、UPDATE、DELETE 操作
- 将变更转换为 JSON 消息，发送到 Kafka

**监听的表：**
- `topics` 表：话题的增删改
- `comments` 表：评论的增删改

**企业中的常见用途：**
- **数据同步**：MySQL → Redis/ES/MongoDB/数仓
- **缓存更新**：MySQL 变更 → 自动刷新 Redis 缓存
- **数据订阅**：业务解耦，多个系统订阅同一份数据
- **实时数仓**：MySQL → Kafka → Flink → ClickHouse
- **审计日志**：记录所有数据变更

**为什么不在代码里双写：**

**双写方案（不推荐）：**
```
写 MySQL → 成功
  ↓
写 ES → 失败怎么办？回滚？
```
- 业务代码耦合严重
- 无法保证原子性（MySQL 写成功，ES 写失败）
- 性能差（同步写，ES 慢会拖慢整个接口）

**Canal 方案（推荐）：**
```
写 MySQL → 成功，返回给用户
  ↓ (异步)
Canal 监听 binlog
  ↓
写 ES（失败可以重试，不影响用户）
```
- 业务代码完全解耦
- 最终一致性（允许短暂不一致）
- 性能好（异步处理）

**面试高频问题：**
- Canal 的工作原理
- 如何保证 MySQL 和 ES 的最终一致性
- 如果 Canal 挂了，重启后如何继续同步
- 双写 vs Canal 的优缺点

---

### 3.3 Zookeeper

**在本项目中的作用：**
- Kafka 的依赖组件（Kafka 3.0 后可选）
- 管理 Kafka 集群元数据：哪些 Broker 在线、Topic 分区信息
- 选举 Controller：谁负责管理分区分配
- 消费者组协调：负责消费者的分区分配（Rebalance）

**企业中的常见用途：**
- **分布式协调**：选举 Leader、分布式锁、配置中心
- **服务注册与发现**：Dubbo 使用 ZooKeeper 做注册中心
- **集群管理**：HBase、HDFS 依赖 ZooKeeper
- **配置管理**：统一配置中心

**为什么需要 Zookeeper：**
- 分布式系统需要一个"协调者"
- 保证分布式一致性（Paxos 算法的实现）

**注意：**
- 你不需要直接操作 ZooKeeper
- 只需要启动它，让 Kafka 能正常工作

---

## 4. 监控运维层

### 4.1 Prometheus

**在本项目中的作用：**
- 系统监控数据采集
- 每 10 秒拉取一次后端的 `/metrics` 接口
- 存储时序数据（带时间戳的历史记录）

**监控的指标：**
1. **请求总数**：`http_requests_total`（按接口、状态码统计）
2. **请求延迟**：`http_request_duration_seconds`（响应时间分布）
3. **并发请求数**：`http_requests_in_progress`（当前正在处理的请求）

**企业中的常见用途：**
- **系统监控**：CPU、内存、磁盘、网络
- **应用监控**：QPS、响应时间、错误率
- **业务监控**：订单量、支付成功率、用户活跃度
- **告警**：配合 Alertmanager 发送告警

**为什么用 Prometheus：**
- 云原生标准：Kubernetes 官方推荐
- 强大的查询语言：PromQL
- 多维度数据：通过标签（Label）灵活查询
- 生态丰富：各种 Exporter（MySQL、Redis、Nginx）

**面试高频问题：**
- Prometheus 的数据模型（指标 + 标签）
- PromQL 常用查询（rate、sum、histogram_quantile）
- Prometheus vs Zabbix/Nagios
- 监控四大黄金指标：延迟、流量、错误、饱和度

---

### 4.2 Grafana

**在本项目中的作用：**
- 监控数据可视化
- 连接 Prometheus，查询监控数据
- 配置各种图表：折线图、柱状图、仪表盘、热力图
- 实时展示系统运行状态

**常见图表：**
1. **QPS 趋势图**：每秒处理多少请求
2. **响应时间曲线**：P50、P95、P99 延迟
3. **错误率仪表盘**：4xx、5xx 错误占比
4. **并发数折线图**：系统负载情况

**企业中的常见用途：**
- **运维大屏**：展示系统健康状态
- **性能分析**：找出慢接口、性能瓶颈
- **容量规划**：预测流量增长，提前扩容
- **故障排查**：通过图表快速定位问题时间点

**为什么用 Grafana：**
- 颜值高：图表美观，支持自定义
- 数据源丰富：支持 Prometheus、MySQL、ES、InfluxDB
- 告警功能：阈值告警、发送邮件/钉钉/Slack
- 开源免费：企业版有更多功能

---

### 4.3 Kafka UI

**在本项目中的作用：**
- Kafka 管理界面（Web UI）
- 查看 Topic 列表、分区、消费者组
- 查看消息内容（调试时非常有用）
- 查看消费进度（Lag）：有没有消息积压

**企业中的常见用途：**
- **运维监控**：查看 Kafka 集群状态
- **问题排查**：查看消息内容，定位数据错误
- **消费者管理**：重置 Offset，重新消费历史消息
- **性能分析**：查看分区分布，优化消费者数量

**为什么需要 UI：**
- Kafka 命令行操作复杂
- 查看消息内容不方便
- 团队协作，运维同学也能用

---

## 5. 容器化部署

### 5.1 Docker

**在本项目中的作用：**
- 将每个服务打包成 Docker 镜像
- 容器化运行：MySQL、Redis、ES、Kafka、Zookeeper、Prometheus、Grafana
- 隔离环境，避免依赖冲突

**企业中的常见用途：**
- **开发环境统一**：新人不需要装一堆软件，docker-compose up 即可
- **持续集成**：CI/CD 流水线中构建镜像
- **微服务部署**：每个服务独立容器，独立扩容
- **资源隔离**：限制 CPU、内存，防止某个服务占满资源

**为什么用 Docker：**
- 环境一致性：开发、测试、生产环境完全一致
- 快速部署：秒级启动
- 资源利用率高：比虚拟机轻量
- 生态成熟：Docker Hub 有海量镜像

---

### 5.2 Docker Compose

**在本项目中的作用：**
- 编排多个 Docker 容器
- 一键启动所有服务：`docker-compose up -d`
- 定义服务依赖：MySQL 启动后再启动后端
- 配置网络和存储卷

**企业中的常见用途：**
- **开发环境**：本地开发时快速启动依赖服务
- **测试环境**：自动化测试时启动完整环境
- **小型项目部署**：单机部署时使用

**生产环境：**
- 大规模生产环境使用 **Kubernetes**（K8s）
- Docker Compose 适合单机或小规模部署

---

## 6. 前端技术

### 6.1 原生 HTML + CSS + JavaScript

**在本项目中的作用：**
- 展示论坛界面：首页、话题详情、发帖页面、登录注册
- 通过 Fetch API 调用后端接口
- 纯静态页面，无需构建工具

**为什么不用 Vue/React：**
- 项目重点是后端架构
- 展示能力：会原生 JS，框架都是工具
- 简单够用：论坛功能不复杂

**企业中的常见用途：**
- **移动端 H5 页面**：活动页、营销页
- **企业官网**：内容展示为主
- **后台管理系统**：配合 Vue/React 开发

---

## 7. 完整数据流

### 场景1：用户发布话题

```
用户点击"发布" 
  ↓
前端发送 POST /api/v1/topics
  ↓
Gin 中间件：JWT 认证 + 限流 + Prometheus 埋点
  ↓
Logic 层：生成 Snowflake ID、计算热度分数
  ↓
写入 MySQL（topics 表）
  ↓ (异步)
Canal 监听 binlog，捕获 INSERT 操作
  ↓
Canal 发消息到 Kafka（topic: bullbell.topics）
  ↓
Go Consumer 消费消息
  ↓
写入 Elasticsearch（索引：bullbell_topics）
  ↓
写入 Redis ZSet（热榜）
  ↓
返回成功给用户
```

---

### 场景2：用户搜索话题

```
用户输入"游戏"，点击搜索
  ↓
前端发送 GET /api/v1/search?keyword=游戏
  ↓
Gin 路由到 SearchController
  ↓
调用 Elasticsearch 查询
  ↓ (multi_match 查询 title + content)
ES 返回匹配结果（按相关性排序）
  ↓
返回给前端（JSON）
  ↓
前端渲染搜索结果（关键词高亮）
```

---

### 场景3：用户点赞话题

```
用户点击"点赞"
  ↓
前端发送 POST /api/v1/topics/{id}/vote?type=upvote
  ↓
Gin 中间件：JWT 认证
  ↓
Logic 层：加分布式锁（防止重复点赞）
  ↓
检查 Redis：用户是否已点赞
  ↓ (未点赞)
开启 MySQL 事务：
  - INSERT votes 表
  - UPDATE topics 表（vote_count +1）
  ↓
提交事务
  ↓
删除 Redis 缓存（该话题的缓存）
  ↓
释放分布式锁
  ↓ (异步)
Canal 监听到 topics 表 UPDATE
  ↓
更新 ES 中的 vote_count
  ↓
更新 Redis ZSet 热榜分数
  ↓
返回成功
```

---

## 8. 技术选型总结

| 技术 | 替代方案 | 为什么选它 | 企业采用率 |
|------|---------|-----------|----------|
| **Go** | Java、Python、Node.js | 性能 + 并发 + 部署简单 | ⭐⭐⭐⭐⭐ |
| **Gin** | Beego、Echo、Chi | 性能第一，轻量级 | ⭐⭐⭐⭐⭐ |
| **MySQL** | PostgreSQL、SQL Server | 生态成熟，社区最大 | ⭐⭐⭐⭐⭐ |
| **Redis** | Memcached、Hazelcast | 数据结构丰富，持久化 | ⭐⭐⭐⭐⭐ |
| **Elasticsearch** | Solr、Algolia、Meilisearch | 功能强大，生态完善 | ⭐⭐⭐⭐⭐ |
| **Kafka** | RabbitMQ、RocketMQ、Pulsar | 高吞吐，大数据首选 | ⭐⭐⭐⭐⭐ |
| **Canal** | Debezium、Maxwell | 阿里开源，文档完善 | ⭐⭐⭐⭐ |
| **Prometheus** | Zabbix、Nagios、Datadog | 云原生标准，K8s 首选 | ⭐⭐⭐⭐⭐ |
| **Grafana** | Kibana、Tableau | 开源免费，颜值高 | ⭐⭐⭐⭐⭐ |
| **Docker** | 虚拟机、裸金属 | 容器化标准，轻量级 | ⭐⭐⭐⭐⭐ |

---

## 9. 面试话术模板

### 开场白（30秒电梯演讲）

> "这是我独立开发的一个 Go 语言论坛系统，采用微服务化的设计思想。
> 
> **技术栈**：Go + Gin + MySQL + Redis + Elasticsearch + Kafka + Prometheus + Grafana，Docker 一键部署。
> 
> **核心亮点**：实现了 MySQL 到 Elasticsearch 的实时数据同步方案，通过 Canal 监听 binlog，推送到 Kafka，再由消费者同步到 ES，保证了数据的最终一致性。
> 
> **性能优化**：Redis 缓存 + 令牌桶限流 + 分布式锁，支持 500 QPS。
> 
> **可观测性**：集成 Prometheus + Grafana 监控，实时追踪 QPS、响应时间、错误率。"

---

### 深度技术点讲解

**面试官问："详细讲讲数据同步方案"**

> "数据同步是这个项目的核心亮点，我解决的问题是：如何保证 MySQL 和 Elasticsearch 的数据一致性。
> 
> **方案选择**：我对比了两种方案：
> 1. **双写**：业务代码同时写 MySQL 和 ES → 耦合严重，无法保证原子性
> 2. **Canal + Kafka**：异步解耦，最终一致性 → 我选择了这个
> 
> **实现细节**：
> 1. Canal 伪装成 MySQL 从库，监听 binlog
> 2. 捕获 topics 和 comments 表的增删改操作
> 3. 转换为 JSON 消息，发送到 Kafka
> 4. Go 消费者从 Kafka 读取消息，解析后写入 ES
> 5. 使用话题 ID 作为文档 ID，保证幂等性（重复消费不会出错）
> 
> **可靠性保证**：
> - Kafka 有消息持久化，消费者挂了不会丢消息
> - Offset 提交机制，重启后从断点继续消费
> - 消费失败会重试，有死信队列兜底
> 
> **实际效果**：数据同步延迟在 100ms 以内，基本实现近实时搜索。"

---

### 技术难点讲解

**面试官问："你遇到最大的技术难点是什么？"**

> "有两个比较有挑战的点：
> 
> **难点1：中文全文搜索**
> - 一开始用 standard 分析器，中文搜索根本查不到
> - 研究了 Elasticsearch 的分词原理后，换成 ngram 分析器
> - 配置 min_gram=2, max_gram=3，解决了单字搜索问题
> - 后续还可以集成 IK 中文分词插件做更精准的搜索
> 
> **难点2：分布式锁防重复投票**
> - 用户快速点击多次点赞，会出现重复投票
> - 用 Redis SETNX 实现分布式锁，设置过期时间防止死锁
> - 用 Lua 脚本保证释放锁的原子性（判断是否是自己的锁 + 删除）
> - 测试了并发场景，100 个并发请求只有 1 个能成功投票
> 
> 这两个问题让我对搜索引擎和分布式系统有了更深的理解。"

---

## 10. 学习路径建议

### 如果要深入某个技术，建议顺序：

1. **先学 Go + Gin**（最核心，必须精通）
   - Go 并发模型（goroutine、channel、sync 包）
   - Gin 路由、中间件、参数绑定
   
2. **然后学 Redis**（高频使用，面试必考）
   - 5 种数据结构的应用场景
   - 缓存更新策略（Cache Aside）
   - 分布式锁的正确实现

3. **再学 MySQL**（基础能力，必须扎实）
   - 索引原理和优化
   - 事务和锁
   - 主从复制和读写分离

4. **接着学 Kafka + Canal**（亮点，面试加分）
   - Kafka 的分区和消费者组
   - 如何保证消息不丢失
   - Canal 的工作原理

5. **最后学 Elasticsearch**（加分项）
   - 倒排索引原理
   - 分词器和分析器
   - 聚合查询

6. **监控部分**（锦上添花）
   - Prometheus 的数据模型
   - PromQL 基础查询
   - Grafana 配置图表

---

## 11. 扩展方向

如果要继续完善这个项目，可以加入：

### 功能扩展
- [ ] 用户关注系统（关注用户、收藏话题）
- [ ] 标签系统（话题打标签）
- [ ] 图片上传（OSS 存储）
- [ ] 私信功能（WebSocket 实时推送）
- [ ] 管理后台（用户管理、内容审核）

### 技术升级
- [ ] 引入 gRPC（微服务间通信）
- [ ] 引入 Kubernetes（容器编排）
- [ ] 引入 MySQL 读写分离（主从架构）
- [ ] 引入 Redis Sentinel（高可用）
- [ ] 引入 Nginx（负载均衡、反向代理）
- [ ] 引入 JWT 刷新机制（双 Token）
- [ ] 引入 ES IK 分词器（更好的中文搜索）
- [ ] 引入分库分表（Sharding-JDBC）

---

## 12. 常见面试问题汇总

### 架构设计类
1. 为什么选择这个技术栈？
2. 如何保证 MySQL 和 ES 的数据一致性？
3. 如果让你设计一个百万用户的论坛，你会怎么做？
4. 你的系统能承受多大并发？瓶颈在哪？
5. 如何做水平扩展（Scale Out）？

### Redis 类
1. Redis 为什么快？
2. 缓存穿透、击穿、雪崩的区别和解决方案？
3. 分布式锁的正确实现？
4. ZSet 的底层实现？
5. Redis 持久化方式？

### MySQL 类
1. 索引失效的场景？
2. 事务隔离级别和脏读、幻读？
3. MySQL 主从复制原理？
4. 慢查询如何优化？
5. binlog 的作用？

### Kafka 类
1. Kafka 如何保证消息不丢失？
2. 如何保证消息顺序？
3. 消费者组的作用？
4. 重复消费如何处理？
5. Kafka vs RabbitMQ？

### Elasticsearch 类
1. 倒排索引原理？
2. 中文分词的挑战？
3. ES 深度分页问题？
4. 如何优化 ES 查询性能？
5. ES 的分片和副本？

### Go 语言类
1. goroutine 和线程的区别？
2. channel 的底层实现？
3. Go 的 GC 机制？
4. defer 的执行顺序？
5. Go 适合什么场景，不适合什么场景？

---

## 总结

这个项目虽然业务简单（论坛系统），但**技术架构完整**：
- ✅ 有数据存储层（MySQL）
- ✅ 有缓存层（Redis）
- ✅ 有搜索层（Elasticsearch）
- ✅ 有消息队列（Kafka）
- ✅ 有监控层（Prometheus + Grafana）
- ✅ 有容器化部署（Docker）

重点不是功能多复杂，而是：
1. **技术栈全面**：覆盖后端常用中间件
2. **有技术亮点**：数据同步、分布式锁、限流、监控
3. **可以落地**：真实可运行，能演示
4. **有思考深度**：知道为什么这么设计，有对比

**对于大四实习生来说，这个项目已经超过 80% 的竞争者。剩下的就是把每个技术点吃透，准备好面试问题的回答。**

加油！🚀

